{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jinhyungnam/Porject2/blob/main/traff_0530.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = \"\"\"\n",
        "+ CutMix \n",
        "\n",
        "\"\"\"\n",
        "# Test"
      ],
      "metadata": {
        "id": "uaL1eHQ_2Hsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# traffic sign down\n",
        "!gdown --id 1ysKr2SJAxGWrdSvoA5fn40jhRQmbPswl\n",
        "!unzip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAWZiAK1gpqT",
        "outputId": "24f3a77a-1c25-45bc-e1b8-bd72ea1376ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ysKr2SJAxGWrdSvoA5fn40jhRQmbPswl\n",
            "To: /content/data.zip\n",
            "100% 215M/215M [00:02<00:00, 98.3MB/s]\n",
            "Archive:  data.zip\n",
            "replace Train/0/00000_00000_00000.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iua0_QK5kvBy",
        "outputId": "09af16e4-092f-46fd-fe51-cf9705554ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.zip  sample_data  Test  Train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxvRMlYYg3QI",
        "outputId": "b2a3c33d-b1ec-44be-b8dd-9f0345e86d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  data.zip\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from os import listdir\n",
        "# from os.path import isfile, join\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# import cv2\n",
        "# from PIL import Image\n",
        "# from sklearn.metrics import f1_score\n",
        "# from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# from tensorflow.keras import Sequential\n",
        "# from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
        "\n",
        "# tf.__version__"
      ],
      "metadata": {
        "id": "HH_ihtIxg-ot",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "3454c07d-e14f-42f2-e7de-6956f557dff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# import os\n",
        "# os.chdir('/content/drive/MyDrive/TA/{Set_Your_Path}')"
      ],
      "metadata": {
        "id": "nLDff6F6jPSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Few imports\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "WlNldQwslnbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Before starting, clear the memory\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "W483Afs65uff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transformations. To begin with, we shall keep it minimum - only resizing the images and converting them to PyTorch tensors\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize([112, 112]),\n",
        "    transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "# # Define transformations\n",
        "\n",
        "# test_transforms = transforms.Compose([\n",
        "#     transforms.Resize([112, 112]),\n",
        "#     transforms.ToTensor()\n",
        "#     ])"
      ],
      "metadata": {
        "id": "mK1s7mDO4rL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSMgz9_042R_",
        "outputId": "49a2fff4-607e-4260-8d24-376aa3391be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'Train', 'Test', 'data.zip', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining hyperparameters\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "learning_rate = 0.001\n",
        "EPOCHS = 15\n",
        "numClasses = 43"
      ],
      "metadata": {
        "id": "7FCbLf9c4zJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define path of training data\n",
        "\n",
        "train_data_path = \"./Train\"\n",
        "train_data = torchvision.datasets.ImageFolder(root = train_data_path, transform = data_transforms)\n",
        "\n",
        "# Divide data into training and validation (0.8 and 0.2)\n",
        "ratio = 0.8\n",
        "n_train_examples = int(len(train_data) * ratio)\n",
        "n_val_examples = len(train_data) - n_train_examples\n",
        "\n",
        "train_data, val_data = data.random_split(train_data, [n_train_examples, n_val_examples])\n",
        "\n",
        "print(f\"Number of training samples = {len(train_data)}\")\n",
        "print(f\"Number of validation samples = {len(val_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur3Skf_a4xiV",
        "outputId": "dc90471c-f589-4938-a2b6-07e59e8a0d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples = 20808\n",
            "Number of validation samples = 5202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot histogram for training and validation data\n",
        "\n",
        "train_hist = [0]*numClasses\n",
        "for i in train_data.indices:\n",
        "    tar = train_data.dataset.targets[i]\n",
        "    train_hist[tar] += 1\n",
        "    \n",
        "val_hist = [0]*numClasses\n",
        "for i in val_data.indices:\n",
        "    tar = val_data.dataset.targets[i]\n",
        "    val_hist[tar] += 1\n",
        "\n",
        "plt.bar(range(numClasses), train_hist, label=\"train\")\n",
        "plt.bar(range(numClasses), val_hist, label=\"val\")\n",
        "legend = plt.legend(loc='upper right', shadow=True)\n",
        "plt.title(\"Distribution Plot\")\n",
        "plt.xlabel(\"Class ID\")\n",
        "plt.ylabel(\"# of examples\")\n",
        "\n",
        "plt.savefig(\"train_val_split.png\", bbox_inches = 'tight', pad_inches=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "sQ2GftmH4wK9",
        "outputId": "0835645a-251c-4f7d-e1ed-eec25f5a954f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loader for training and validation\n",
        "\n",
        "train_loader = data.DataLoader(train_data, shuffle=True, batch_size = BATCH_SIZE)\n",
        "val_loader = data.DataLoader(val_data, shuffle=True, batch_size = BATCH_SIZE)"
      ],
      "metadata": {
        "id": "DqQOw8924wIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to count the number of parameters in the model\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "Br_3x46J4wF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class AlexnetTS(nn.Module):\n",
        "    def __init__(self, output_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, padding=1),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            )\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256*7*7, 1000),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(in_features=1000, out_features=256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Linear(256, output_dim)\n",
        "            )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.classifier(h)\n",
        "        return x, h"
      ],
      "metadata": {
        "id": "TlXzwNCO6Ir9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "# The model is defined in the class AlexnetTS in the file class_alexnetTS.py\n",
        "\n",
        "model = AlexnetTS(numClasses)\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqKrS1iv4wDN",
        "outputId": "f0f56231-5206-46d9-c8a9-aa73bc59dc5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 15,063,891 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer and criterion functions\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "OZi1GxqH4v_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If CUDA is available, convert model and loss to cuda variables\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "\n",
        "# Print model\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ8nT8kz4v8t",
        "outputId": "3db7ec8d-9ca3-4410-efe7-6fde74f29eb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlexnetTS(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=12544, out_features=1000, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=1000, out_features=256, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=256, out_features=43, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print summary of the model for the given dimension of the image\n",
        "\n",
        "print(summary(model, (3, 112, 112))) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAj8d_4Q6Ord",
        "outputId": "79e610d2-3fb6-4847-e7a7-d5c2e859fa5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]           1,792\n",
            "         MaxPool2d-2           [-1, 64, 28, 28]               0\n",
            "              ReLU-3           [-1, 64, 28, 28]               0\n",
            "            Conv2d-4          [-1, 192, 28, 28]         110,784\n",
            "         MaxPool2d-5          [-1, 192, 14, 14]               0\n",
            "              ReLU-6          [-1, 192, 14, 14]               0\n",
            "            Conv2d-7          [-1, 384, 14, 14]         663,936\n",
            "              ReLU-8          [-1, 384, 14, 14]               0\n",
            "            Conv2d-9          [-1, 256, 14, 14]         884,992\n",
            "             ReLU-10          [-1, 256, 14, 14]               0\n",
            "           Conv2d-11          [-1, 256, 14, 14]         590,080\n",
            "        MaxPool2d-12            [-1, 256, 7, 7]               0\n",
            "             ReLU-13            [-1, 256, 7, 7]               0\n",
            "          Dropout-14                [-1, 12544]               0\n",
            "           Linear-15                 [-1, 1000]      12,545,000\n",
            "             ReLU-16                 [-1, 1000]               0\n",
            "          Dropout-17                 [-1, 1000]               0\n",
            "           Linear-18                  [-1, 256]         256,256\n",
            "             ReLU-19                  [-1, 256]               0\n",
            "           Linear-20                   [-1, 43]          11,051\n",
            "================================================================\n",
            "Total params: 15,063,891\n",
            "Trainable params: 15,063,891\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.14\n",
            "Forward/backward pass size (MB): 6.63\n",
            "Params size (MB): 57.46\n",
            "Estimated Total Size (MB): 64.24\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print model's state dict\n",
        "\n",
        "print(\"Model's state dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU1UctZw6OpK",
        "outputId": "b101e54d-2277-4377-ce49-937e6e04e67c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's state dict:\n",
            "features.0.weight \t torch.Size([64, 3, 3, 3])\n",
            "features.0.bias \t torch.Size([64])\n",
            "features.3.weight \t torch.Size([192, 64, 3, 3])\n",
            "features.3.bias \t torch.Size([192])\n",
            "features.6.weight \t torch.Size([384, 192, 3, 3])\n",
            "features.6.bias \t torch.Size([384])\n",
            "features.8.weight \t torch.Size([256, 384, 3, 3])\n",
            "features.8.bias \t torch.Size([256])\n",
            "features.10.weight \t torch.Size([256, 256, 3, 3])\n",
            "features.10.bias \t torch.Size([256])\n",
            "classifier.1.weight \t torch.Size([1000, 12544])\n",
            "classifier.1.bias \t torch.Size([1000])\n",
            "classifier.4.weight \t torch.Size([256, 1000])\n",
            "classifier.4.bias \t torch.Size([256])\n",
            "classifier.6.weight \t torch.Size([43, 256])\n",
            "classifier.6.bias \t torch.Size([43])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print optimizer details\n",
        "\n",
        "print(\"Optimizer details:\")\n",
        "print(optimizer)\n",
        "print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n29THZdR6Omp",
        "outputId": "6f863381-68ff-4bce-ac4d-62ad6b09336d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer details:\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate accuracy\n",
        "\n",
        "def calculate_accuracy(y_pred, y):\n",
        "    top_pred = y_pred.argmax(1, keepdim = True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc"
      ],
      "metadata": {
        "id": "4udNIGcd6Okp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform training of the model\n",
        "\n",
        "def train(model, loader, opt, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # Train the model\n",
        "    model.train()\n",
        "    \n",
        "    for (images, labels) in loader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        \n",
        "        # Training pass\n",
        "        opt.zero_grad()\n",
        "        \n",
        "        output, _ = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        \n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        \n",
        "        # Calculate accuracy\n",
        "        acc = calculate_accuracy(output, labels)\n",
        "        \n",
        "        # Optimizing weights\n",
        "        opt.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(loader), epoch_acc / len(loader)"
      ],
      "metadata": {
        "id": "CV-i2c9r6Ohq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform evaluation on the trained model\n",
        "\n",
        "def evaluate(model, loader, opt, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for (images, labels) in loader:\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "            \n",
        "            # Run predictions\n",
        "            output, _ = model(images)\n",
        "            loss = criterion(output, labels)\n",
        "            \n",
        "            # Calculate accuracy\n",
        "            acc = calculate_accuracy(output, labels)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    \n",
        "    return epoch_loss / len(loader), epoch_acc / len(loader)"
      ],
      "metadata": {
        "id": "HUgvxmLZ6dKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform training\n",
        "\n",
        "# List to save training and val loss and accuracies\n",
        "train_loss_list = [0]*EPOCHS\n",
        "train_acc_list = [0]*EPOCHS\n",
        "val_loss_list = [0]*EPOCHS\n",
        "val_acc_list = [0]*EPOCHS\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"Epoch-%d: \" % (epoch))\n",
        "\n",
        "    train_start_time = time.monotonic()\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
        "    train_end_time = time.monotonic()\n",
        "\n",
        "    val_start_time = time.monotonic()\n",
        "    val_loss, val_acc = evaluate(model, val_loader, optimizer, criterion)\n",
        "    val_end_time = time.monotonic()\n",
        "    \n",
        "    train_loss_list[epoch] = train_loss\n",
        "    train_acc_list[epoch] = train_acc\n",
        "    val_loss_list[epoch] = val_loss\n",
        "    val_acc_list[epoch] = val_acc\n",
        "    \n",
        "    print(\"Training: Loss = %.4f, Accuracy = %.4f, Time = %.2f seconds\" % (train_loss, train_acc, train_end_time - train_start_time))\n",
        "    print(\"Validation: Loss = %.4f, Accuracy = %.4f, Time = %.2f seconds\" % (val_loss, val_acc, val_end_time - val_start_time))\n",
        "    print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io7bYHm56dHf",
        "outputId": "437bb001-4341-410d-e1fe-9ea1483d4102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch-0: \n",
            "Training: Loss = 3.4741, Accuracy = 0.0617, Time = 24.93 seconds\n",
            "Validation: Loss = 3.3029, Accuracy = 0.0784, Time = 4.59 seconds\n",
            "\n",
            "Epoch-1: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model\n",
        "\n",
        "# Create folder to save model\n",
        "MODEL_FOLDER = \"../Model\"\n",
        "if not os.path.isdir(MODEL_FOLDER):\n",
        "    os.mkdir(MODEL_FOLDER)\n",
        "    \n",
        "PATH_TO_MODEL = MODEL_FOLDER + \"/pytorch_classification_alexnetTS.pth\"\n",
        "if os.path.exists(PATH_TO_MODEL):\n",
        "    os.remove(PATH_TO_MODEL)\n",
        "torch.save(model.state_dict(), PATH_TO_MODEL)\n",
        "\n",
        "print(\"Model saved at %s\" %(PATH_TO_MODEL))"
      ],
      "metadata": {
        "id": "dcQql-6A6dDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss and accuracies for training and validation data\n",
        "\n",
        "_, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Loss plot\n",
        "axs[0].plot(train_loss_list, label=\"train\")\n",
        "axs[0].plot(val_loss_list, label=\"val\")\n",
        "axs[0].set_title(\"Plot - Loss\")\n",
        "axs[0].set_xlabel(\"Epochs\")\n",
        "axs[0].set_ylabel(\"Loss\")\n",
        "legend = axs[0].legend(loc='upper right', shadow=False)\n",
        "\n",
        "# Accuracy plot\n",
        "axs[1].plot(train_acc_list, label=\"train\")\n",
        "axs[1].plot(val_acc_list, label=\"val\")\n",
        "axs[1].set_title(\"Plot - Accuracy\")\n",
        "axs[1].set_xlabel(\"Epochs\")\n",
        "axs[1].set_ylabel(\"Accuracy\")\n",
        "legend = axs[1].legend(loc='center right', shadow=True)"
      ],
      "metadata": {
        "id": "AJ8oUwt36auj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "enSqV0IF6ayh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mlkhpz_E6a2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cEp76Ytr6a5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cnEmX-M76a80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WyYFvJyI6a_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ABN_kY2x6bCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RVSRSP2U6Odb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7MGJ3BMm4v0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "labels = []\n",
        "\n",
        "height = 30\n",
        "width = 30\n",
        "channels = 3\n",
        "num_classes = 43\n",
        "\n",
        "for i in range(num_classes) :\n",
        "    path = f'./data/Train/{i}/'\n",
        "    path = f'./Train/{i}/'\n",
        "    Class = os.listdir(path)\n",
        "    for a in Class:\n",
        "        image = cv2.imread(path + a)\n",
        "        image_from_array = Image.fromarray(image, 'RGB')\n",
        "        size_image = image_from_array.resize((height, width))\n",
        "        data.append(np.array(size_image))\n",
        "        labels.append(i)\n",
        "\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "TQC5TWM-g5LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgQGwIu5lQM2",
        "outputId": "b1628e79-45a7-4910-b747-c481894915de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26010, 30, 30, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_Lqq8iEjZgM",
        "outputId": "868804fe-8de3-4d1d-a325-26b307c120c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26010,)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wzp-s0g-lRsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4o89zSJRhG4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HGxXX1rEhGyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaidPOe7h3Q5"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import (RandomForestRegressor, GradientBoostingRegressor, \n",
        "                              AdaBoostRegressor)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfdkTsuSh49_"
      },
      "outputs": [],
      "source": [
        "training_data = pd.read_csv('train_data.csv')\n",
        "test_input_data = pd.read_csv('test_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Signal shift off\n",
        "# train_x = np.array(training_data.values[:,3:], dtype=np.float64)\n",
        "# train_y = np.array(training_data.values[:,2], dtype=np.float64)\n",
        "# # test_x = np.array(test_input_data.values[:,18:], dtype=np.float64)\n",
        "# test_x = np.array(test_input_data.values[:,2:], dtype=np.float64)"
      ],
      "metadata": {
        "id": "Vvlpd1ofYRX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Signal shift on\n",
        "# cols = ['s1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14', 's15', 's16']\n",
        "# for s in cols:\n",
        "#     training_data['shf_{}'.format(s)] = training_data['{}'.format(s)].shift(-2000)\n",
        "#     test_input_data['shf_{}'.format(s)] = test_input_data['{}'.format(s)].shift(-2000)\n",
        "# training_data = training_data.dropna()\n",
        "# test_input_data = test_input_data.fillna(0)\n",
        "\n",
        "# train_x = np.array(training_data.values[:,19:], dtype=np.float64)\n",
        "# train_y = np.array(training_data.values[:,2], dtype=np.float64)\n",
        "# test_x = np.array(test_input_data.values[:,18:], dtype=np.float64)\n",
        "# # test_x = np.array(test_input_data.values[:,2:], dtype=np.float64)"
      ],
      "metadata": {
        "id": "wa0PGmLq42NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = np.array(training_data.values[:,3:], dtype=np.float64)\n",
        "train_y = np.array(training_data.values[:,2], dtype=np.float64)\n",
        "test_x = np.array(test_input_data.values[:,2:], dtype=np.float64)"
      ],
      "metadata": {
        "id": "kb6boIiFHVfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvcoUqf6iQiN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # filtering on\n",
        "# from scipy.signal import butter, filtfilt, square\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # b, a = butter(4, 0.0055/(100/2), btype='low', analog=False)  # fs = 100 Hz, fc = 0.005 Hz\n",
        "# b, a = butter(4, 1/(100/2), btype='low', analog=False)  # fs = 100 Hz, fc = 1 Hz\n",
        "# filt_train_data = np.array([filtfilt(b, a, train_x[:,i]) for i in range(len(train_x[0]))]).T\n",
        "# train_x = filt_train_data\n",
        "# filt_test_data = np.array([filtfilt(b, a, test_x[:,i]) for i in range(len(test_x[0]))]).T\n",
        "# test_x = filt_test_data\n"
      ],
      "metadata": {
        "id": "3LZJi35dt-0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fOMYzOR2a_C"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler().fit(train_x)\n",
        "train_x = scaler.transform(train_x)\n",
        "test_x = scaler.transform(test_x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_p = int(len(train_x)*0.2)\n",
        "\n",
        "train1_x = train_x[:split_p*1,:] \n",
        "train2_x = train_x[split_p*2:,:] \n",
        "train_x_t = np.concatenate([train1_x,train2_x])\n",
        "train_x_v = train_x[split_p*1:split_p*2,:]\n",
        "\n",
        "train1_y = train_y[:split_p*1] \n",
        "train2_y = train_y[split_p*2:] \n",
        "train_y_t = np.concatenate([train1_y,train2_y],)\n",
        "train_y_v = train_y[split_p*1:split_p*2]"
      ],
      "metadata": {
        "id": "nDveRodLYw4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset(data, label, window_size=20):\n",
        "    feature_list = []\n",
        "    label_list = []\n",
        "    for i in range(len(data) - window_size):\n",
        "        feature_list.append(data[i:i+window_size+1])\n",
        "        label_list.append(label[i:i+window_size])\n",
        "    return np.array(feature_list), np.array(label_list)\n",
        "\n",
        "def make_dataset2(data, window_size=20):\n",
        "    feature_list = []\n",
        "    for i in range(len(data) - window_size):\n",
        "        feature_list.append(data[i:i+window_size+1])\n",
        "    return np.array(feature_list)"
      ],
      "metadata": {
        "id": "bKM3PlMa4Mnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_t_seq, train_y_t_seq = make_dataset(train_x_t, train_y_t, 30)\n",
        "train_x_v_seq, train_y_v_seq = make_dataset(train_x_v, train_y_v, 30)\n",
        "train_x_seq, train_y_seq = make_dataset(train_x, train_y, 30)\n",
        "\n",
        "print(train_x_t_seq.shape)\n",
        "print(train_y_t_seq.shape)\n",
        "print(train_x_v_seq.shape)\n",
        "print(train_y_v_seq.shape)\n",
        "print(train_x_seq.shape)\n",
        "print(train_y_seq.shape)\n",
        "\n",
        "test_x_seq = make_dataset2(test_x, 30)\n",
        "test_x_seq.shape"
      ],
      "metadata": {
        "id": "VgtJpSA052vh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4cebafd-6adc-469e-9a0b-e7fb4436e2d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2693257, 31, 16)\n",
            "(2693257, 30)\n",
            "(673291, 31, 16)\n",
            "(673291, 30)\n",
            "(3366578, 31, 16)\n",
            "(3366578, 30)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(841623, 31, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XD8T3t9Z8atI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Flatten\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import LSTM\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.layers import Dense, Activation, Flatten, Conv1D, MaxPooling1D, BatchNormalization, Dropout"
      ],
      "metadata": {
        "id": "YimUrMuR8zzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ybn-T1OJxEJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    model_cnn =Sequential()\n",
        "    # model_cnn.add(Conv1D(input_shape = (train_feature.shape[1], train_feature.shape[2]), \n",
        "    #                         filters=64,kernel_size=3,activation='relu'))\n",
        "    model_cnn.add(Conv1D(input_shape = (train_x_t_seq.shape[1], train_x_t_seq.shape[2]), \n",
        "                            filters=64,kernel_size=3,activation='relu'))\n",
        "    #model_cnn.add(BatchNormalization())\n",
        "    model_cnn.add(MaxPooling1D(pool_size = 2))\n",
        "    # model_cnn.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "    model_cnn.add(Conv1D(filters=32,kernel_size=3,activation='relu'))\n",
        "    #model_cnn.add(BatchNormalization())\n",
        "    model_cnn.add(MaxPooling1D(pool_size = 2))\n",
        "    # model_cnn.add(Dropout(0.25))\n",
        "\n",
        "    #model_cnn.add(Conv1D(filters=16,kernel_size=3,activation='relu'))\n",
        "    #model_cnn.add(MaxPooling1D(pool_size = 2))\n",
        "    #model_cnn.add(Dropout(0.25))\n",
        "\n",
        "    model_cnn.add(Flatten())\n",
        "    model_cnn.add(Dense(1000))\n",
        "    # model_cnn.add(Dropout(0.25))\n",
        "    model_cnn.add(Activation('relu'))\n",
        "\n",
        "    model_cnn.add(Dense(1))\n",
        "    model_cnn.add(Activation('linear'))\n",
        "    model_cnn.summary()\n",
        "    ###############3\n",
        "    ################3\n",
        "    import os\n",
        "    model_cnn.compile(loss='mean_absolute_error', optimizer='adam')\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "    model_path = '/content/'\n",
        "    filename = os.path.join(model_path, 'tmp_checkpoint_cnn_all_shft.h5')\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "    # history = model_cnn.fit(train_x_seq, train_y_seq,\n",
        "    history = model_cnn.fit(train_x_t_seq, train_y_t_seq,\n",
        "                                        epochs=1, \n",
        "                                        # epochs=200, \n",
        "                                        batch_size=16,\n",
        "                                        validation_data=(train_x_v_seq, train_y_v_seq), \n",
        "                                        callbacks=[early_stop, checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hj6NCY6NHSxd",
        "outputId": "1b513d99-39f2-4680-9fe6-b24296cbc5bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 29, 64)            3136      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 14, 64)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 12, 32)            6176      \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 6, 32)            0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 192)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              193000    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 1000)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 1001      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 203,313\n",
            "Trainable params: 203,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "168329/168329 [==============================] - ETA: 0s - loss: 30.9348\n",
            "Epoch 1: val_loss improved from inf to 24.17129, saving model to /content/tmp_checkpoint_cnn_all_shft.h5\n",
            "168329/168329 [==============================] - 601s 4ms/step - loss: 30.9348 - val_loss: 24.1713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4xL0qlXHZB-",
        "outputId": "09298bb9-364f-4e47-ae6b-e64546fb1e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101672/168230 [=================>............] - ETA: 4:06 - loss: 13.4920"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn.load_weights(filename)\n",
        "pred = model_cnn.predict(test_x_seq)\n",
        "print(pred.shape)\n",
        "print(pred.min(), pred.max())"
      ],
      "metadata": {
        "id": "dFpkiS8MHjV1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9230ab5-4aa9-471b-a7ca-0c24e6f5254d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(841623, 1)\n",
            "-16.014948 533.835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def post_process_pred_ver2(y_pred, y_class_val_list):\n",
        "#     \"\"\"\n",
        "#     use 'train_y' for 'y_class_val_list'\n",
        "#     \"\"\"\n",
        "#     y_cls = np.sort(np.unique(y_class_val_list))\n",
        "#     y_cls_mid = [(y_cls[i] + y_cls[i + 1])/2 for i in range(len(y_cls) - 1)]\n",
        "#     y_pred_mapped = y_cls[np.searchsorted(y_cls_mid, y_pred)]\n",
        "#     return y_pred_mapped\n",
        "\n",
        "# pred2 = post_process_pred_ver2(pred, np.unique(train_y))\n"
      ],
      "metadata": {
        "id": "Mtn3XAPVjJRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_submission = pd.read_csv('sample_solution.csv')\n",
        "# pred = np.pad(pred, ((0,sample_submission.shape[0]-pred.shape[0]),(0,0)), 'constant', constant_values=0)"
      ],
      "metadata": {
        "id": "6pf9mXWGHS-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_submission['CO'] = pred\n",
        "# sample_submission.to_csv('predicted_output.csv', index=False) \n",
        "# !kaggle competitions submit -c 2022-samsung-ds-competition-co-gas-data -f predicted_output.csv -m \"Test\""
      ],
      "metadata": {
        "id": "RnWeDDUk-mWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(pred3.min(), pred3.max())"
      ],
      "metadata": {
        "id": "rCos4QsusiPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(np.unique(pred3))"
      ],
      "metadata": {
        "id": "n8OsZ_NpsmDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.unique(pred3)"
      ],
      "metadata": {
        "id": "UF-_trDfsxMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Y_PRED_CLASSIFIER:\n",
        "    def __init__(self, y_pred, y_real):\n",
        "        self.y_pred_clf = self.create_y_pred_clf(y_pred, y_real)\n",
        "\n",
        "    def create_y_pred_clf(self, y_pred, y_real):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        from sklearn.naive_bayes import GaussianNB\n",
        "        y_pred_clf = GaussianNB().fit(y_pred.reshape(-1, 1), y_real.astype(str))\n",
        "        return y_pred_clf\n",
        "\n",
        "    def post_process_pred_ver4(self, y_pred):\n",
        "        \"\"\"\n",
        "        y_pred_clf = create_y_pred_clf(y_pred, y_real):\n",
        "        \"\"\"\n",
        "        y_pred_mapped = self.y_pred_clf.predict(y_pred.reshape(-1, 1)).astype(float)\n",
        "        return y_pred_mapped\n",
        "      "
      ],
      "metadata": {
        "id": "5Gz5LhQD6PeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp = model_cnn.predict(train_x_seq)\n",
        "pp2 = np.pad(pp, ((0,train_y.shape[0]-pp.shape[0]),(0,0)), 'constant', constant_values=0)\n",
        "pp3 = np.squeeze(pp2)\n",
        "y_pred_clf = Y_PRED_CLASSIFIER(pp3, train_y) ## create y pred clf \n",
        "y_pred = y_pred_clf.post_process_pred_ver4(pred)  # using y pred clf"
      ],
      "metadata": {
        "id": "Iu6-vAT06Rog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IhNFMbaD9sF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission = pd.read_csv('sample_solution.csv')"
      ],
      "metadata": {
        "id": "8bmVd1E0CInc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred2 = np.pad(y_pred, ((0,sample_submission.shape[0]-y_pred.shape[0])), 'constant', constant_values=0)"
      ],
      "metadata": {
        "id": "aaJboH8x-y4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission['CO'] = y_pred2  #pred3\n",
        "sample_submission.to_csv('predicted_output.csv', index=False) \n",
        "!kaggle competitions submit -c 2022-samsung-ds-competition-co-gas-data -f predicted_output.csv -m \"Test\""
      ],
      "metadata": {
        "id": "Qt1FY5mG_Lbi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce5abc8d-ea27-4f87-8e0d-fcdf911860ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 10.3M/10.3M [00:02<00:00, 4.77MB/s]\n",
            "Successfully submitted to 2022 Samsung DS competition - CO gas data"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(y_pred2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LHL6Gfyghmpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(pred)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CEl40pVthoVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7NjjRnB242_"
      },
      "outputs": [],
      "source": [
        "# multioutputregressor = xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "#               max_depth = 10, alpha = 10, n_estimators = 100, eval_metric='mae')\n",
        "# multioutputregressor.fit(x_train, y_train\n",
        "#                       ,eval_set=[(x_test, y_test)],\n",
        "#                        early_stopping_rounds = 10, eval_metric='mae')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(train_y)"
      ],
      "metadata": {
        "id": "bLloDJkG5E4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################"
      ],
      "metadata": {
        "id": "cGfJ7z0pY529"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "print(datetime.datetime.now())"
      ],
      "metadata": {
        "id": "Sqn5OU0Djg_V"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "traff_0530.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}