{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1ZaCh4knZbSw"
      },
      "outputs": [],
      "source": [
        "# ver04\n",
        "# image 변주를 주고, smote로 해봄 acc 97.5 f1 95? 나오지만 정말 이상한 데이터들은 못찾음\n",
        "# filename\tanswer\t비슷\tpred\tsum\t\n",
        "# 00198.png\t18\t11,28\t11\t28\t가려진거\n",
        "# 00829.png\t27\t30\t30\t27\t절반 그림자\n",
        "# 00072.png\t30\t28,31\t11\t25\t흐림\n",
        "# 01079.png\t21\t14\t41\t15\t배경다르고 가운데 모양만있음\n",
        "# 02635.png\t5\t4\t2\t13\t너무 흐림\n",
        "# 00033.png\t23\t31\t31\t12\t안보임\n",
        "# 00790.png\t2\t31\t3\t11\t어두움\n",
        "# 00050.png\t25\t11\t2\t9\t가려지고 너무흐림\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\t\n",
        "# 8297\t\t\t\t\t말도안됨\n",
        "\t\n",
        "# \t\t\t\t\t가운데만 Crop해보고 시도하고\n",
        "# \t\t\t\t\t해상도 올리는걸 Test에도?\n",
        "# 0601 22 Test data 해상도만 올려서 해보자\n",
        "\n",
        "# data_transforms_rand = transforms.Compose([\n",
        "#   transforms.RandomRotation(degrees=15),\n",
        "#   transforms.RandomAutocontrast(),\n",
        "#   transforms.RandomAdjustSharpness(4),\n",
        "#   transforms.Resize([112, 112]),\n",
        "#   transforms.Pad(10),\n",
        "#   transforms.ToTensor()\n",
        "#   # transforms.Normalize(0, 1)\n",
        "#   ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uaL1eHQ_2Hsf"
      },
      "outputs": [],
      "source": [
        "_ = \"\"\"\n",
        "+ CutMix \n",
        "+ data_aug\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAWZiAK1gpqT",
        "outputId": "e891f612-b0f4-40de-d0d8-b91fc017bf47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1ysKr2SJAxGWrdSvoA5fn40jhRQmbPswl \n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-MsSMJqE8AdMQYgS_tiYiaeTkiF4WB5F\n",
            "To: /content/Test_Label.csv\n",
            "100% 118k/118k [00:00<00:00, 84.1MB/s]\n",
            "Archive:  data.zip\n",
            "replace Train/0/00000_00000_00000.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "# traffic sign down\n",
        "!gdown --id 1ysKr2SJAxGWrdSvoA5fn40jhRQmbPswl\n",
        "!gdown --id 1-MsSMJqE8AdMQYgS_tiYiaeTkiF4WB5F\n",
        "!unzip data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iua0_QK5kvBy",
        "outputId": "05a945f2-248f-48fc-ed03-4fabff52e737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.zip  sample_data  Test  Test_Label.csv  Train\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WlNldQwslnbJ"
      },
      "outputs": [],
      "source": [
        "# Few imports\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.utils.data as data\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "from __future__ import print_function\n",
        "\n",
        "import zipfile\n",
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6xs5fWsR9lGR"
      },
      "outputs": [],
      "source": [
        "# # https://pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "# # REPRODUCIBILITY\n",
        "# # Controlling sources of randomness\n",
        "def set_seed(RANDOM_SEED=333):\n",
        "    torch.manual_seed(RANDOM_SEED)\n",
        "    torch.cuda.manual_seed(RANDOM_SEED)\n",
        "    torch.cuda.manual_seed_all(RANDOM_SEED) # if use multi-GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(RANDOM_SEED)\n",
        "    random.seed(RANDOM_SEED)\n",
        "    os.environ['PYTHONHASHEED'] = str(RANDOM_SEED)\n",
        "    \n",
        "set_seed()\n",
        "\n",
        "# torch.manual_seed(RANDOM_SEED)\n",
        "# torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "# random.seed(RANDOM_SEED)\n",
        "# np.random.seed(RANDOM_SEED)\n",
        "\n",
        "# def seed_worker(worker_id):\n",
        "#     worker_seed = torch.initial_seed() % 2**32\n",
        "#     np.random.seed(worker_seed)\n",
        "#     random.seed(worker_seed)\n",
        "\n",
        "\n",
        "\n",
        "# # reduced performance\n",
        "# # torch.backends.cudnn.deterministic = True # torch.use_deterministic_algorithms(True)\n",
        "# # torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "W483Afs65uff"
      },
      "outputs": [],
      "source": [
        "# Before starting, clear the memory\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BEkDXPS9SNU",
        "outputId": "7031df5c-d7d7-45ca-f148-d6cbb1a309c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples = 26010\n"
          ]
        }
      ],
      "source": [
        "# Define path of training data\n",
        "train_data_path = \"./Train\"\n",
        "data_transformer_stat = transforms.Compose([transforms.ToTensor()])\n",
        "train_data_stat = torchvision.datasets.ImageFolder(root = train_data_path, transform = data_transformer_stat)\n",
        "print(f\"Number of training samples = {len(train_data_stat)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbDucKgu9-78"
      },
      "outputs": [],
      "source": [
        "# calculate the mean and standard deviation of train_data_stat\n",
        "\n",
        "meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x,_ in train_data_stat]\n",
        "stdRGB = [np.std(x.numpy(), axis=(1,2)) for x,_ in train_data_stat]\n",
        "\n",
        "meanR = np.mean([m[0] for m in meanRGB])\n",
        "meanG = np.mean([m[1] for m in meanRGB])\n",
        "meanB = np.mean([m[2] for m in meanRGB])\n",
        "\n",
        "stdR = np.mean([s[0] for s in stdRGB])\n",
        "stdG = np.mean([s[1] for s in stdRGB])\n",
        "stdB = np.mean([s[2] for s in stdRGB])\n",
        "\n",
        "print(meanR, meanG, meanB)\n",
        "print(stdR, stdG, stdB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mK1s7mDO4rL5"
      },
      "outputs": [],
      "source": [
        "# Define the transformations. To begin with, we shall keep it minimum - only resizing the images and converting them to PyTorch tensors\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize([48, 48]),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB])\n",
        "    ])\n",
        "\n",
        "# # Define transformations\n",
        "\n",
        "data_transforms_rand = transforms.Compose([\n",
        "  transforms.RandomOrder([\n",
        "    transforms.RandomApply([\n",
        "        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n",
        "        transforms.RandomAffine(20, shear=20),\n",
        "        transforms.RandomAutocontrast(),\n",
        "        transforms.RandomAdjustSharpness(4),\n",
        "        transforms.RandomErasing(p=0.05, scale=(0.02, 0.33), value=0),\n",
        "        transforms.GaussianBlur(kernel_size=(3, 3), sigma=(1, 3))\n",
        "    ], p=0.7)\n",
        "  ]),\n",
        "  # transforms.CenterCrop(112*0.8),\n",
        "  # transforms.Resize([112, 112]),\n",
        "  transforms.Resize([48, 48]),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB])\n",
        "])\n",
        "\n",
        "data_transforms_rand2 = transforms.Compose([\n",
        "  transforms.Grayscale(num_output_channels=3), \n",
        "  transforms.Resize([48, 48]),  \n",
        "  # transforms.CenterCrop(112*0.8),\n",
        "  # transforms.Resize([112, 112]),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB])\n",
        "  ])\n",
        "\n",
        "data_transforms_rand3 = transforms.Compose([\n",
        "  transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),\n",
        "  transforms.Resize([48, 48]),  \n",
        "  # transforms.CenterCrop(112*0.8),\n",
        "  # transforms.Resize([112, 112]),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB])\n",
        "  ])\n",
        "\n",
        "\n",
        "# data_transforms_rand_old = transforms.Compose([\n",
        "#   transforms.RandomRotation(degrees=15),\n",
        "#   transforms.RandomAutocontrast(),\n",
        "#   transforms.RandomAdjustSharpness(4),\n",
        "#   transforms.Resize([112, 112]),\n",
        "#   transforms.GaussianBlur(kernel_size=(7, 7), sigma=(2, 4)),\n",
        "#   # transforms.CenterCrop(112*0.8),\n",
        "#   # transforms.Resize([112, 112]),\n",
        "#   transforms.ToTensor(),\n",
        "#   transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB])\n",
        "#   ])\n",
        "\n",
        "# CenterCrop(size) #Crops the given image at the center.transforms.CenterCrop((40, 40)),\n",
        "# ColorJitter([brightness, contrast, …]) #Randomly change the brightness, contrast, saturation and hue of an image.\n",
        "# Grayscale([num_output_channels]) #Convert image to grayscale.\n",
        "\n",
        "\n",
        "# RandomRotation \n",
        "#transform = transforms.RandomRotation(180) #-degree, +degree 사이만큼 회전\n",
        "#ramdomaffine(회전+기울이기 옵션)\n",
        "#transform = transforms.RandomAffine(180, shear=20)\n",
        "\n",
        "# RandomApply(확률에 따라 여러개가 적용될수도 )\n",
        "# transform = transforms.RandomApply([\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.RandomVerticalFlip(),\n",
        "#     transforms.RandomRotation(180),\n",
        "# ], p=0.9)\n",
        "# RandomChoice (하나만 랜덤 선택)\n",
        "# transform = transforms.RandomChoice([\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.RandomVerticalFlip(),\n",
        "#     transforms.RandomRotation(180),\n",
        "# ])\n",
        "\n",
        "# RandomOrder #주어진 transform들을 모두 적용하는데, 그 순서를 랜덤하게 설정한다.\n",
        "#내부적으로 random.shuffle을 사용하고 있다.\n",
        "# transform = transforms.RandomOrder([\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.RandomVerticalFlip(),\n",
        "#     transforms.RandomRotation(180),\n",
        "#     transforms.RandomCrop((60, 60)),\n",
        "# ])\n",
        "\n",
        "# RandomGrayscale #ransform = transforms.RandomGrayscale(p=0.75)\n",
        "# RandomAdjustSharpness0은 blurred, 1은 원본, 2부터는 선명한 정도를 2의 배수만큼 적용하는 것 같다.\n",
        "# RandomAutocontrast\n",
        "# RandomEqualize\n",
        "#transform = transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET) 자동으로 augmentation\n",
        "\n",
        "# adjust_brightness(img, brightness_factor)\n",
        "# adjust_contrast(img, contrast_factor)\n",
        "# adjust_gamma(img, gamma[, gain])\n",
        "# adjust_sharpness(img, sharpness_factor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSMgz9_042R_"
      },
      "outputs": [],
      "source": [
        "print(os.getcwd())\n",
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FCbLf9c4zJb"
      },
      "outputs": [],
      "source": [
        "# Defining hyperparameters\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "learning_rate = 0.001\n",
        "EPOCHS = 15\n",
        "numClasses = 43"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ur3Skf_a4xiV"
      },
      "outputs": [],
      "source": [
        "# Define path of training data\n",
        "\n",
        "train_data_path = \"./Train\"\n",
        "train_data_all = torchvision.datasets.ImageFolder(root = train_data_path, transform = data_transforms)\n",
        "print(f\"Number of training samples = {len(train_data_all)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezMmeVXFjoQz"
      },
      "outputs": [],
      "source": [
        "import sympy\n",
        "\n",
        "mul_num = 3\n",
        "lst_aug = [train_data_all]\n",
        "for i in range(mul_num) :\n",
        "  set_seed(i)\n",
        "  rand_prinm = sympy.randprime(0, 10000)\n",
        "  print(str(i) + ' : ' + str(rand_prinm))#, end = ', ')\n",
        "  set_seed(rand_prinm)\n",
        "  if i ==1 :\n",
        "      train_data_aug = torchvision.datasets.ImageFolder(root = train_data_path, transform = data_transforms_rand2)    \n",
        "  else:\n",
        "      train_data_aug = torchvision.datasets.ImageFolder(root = train_data_path, transform = data_transforms_rand)\n",
        "  lst_aug.append(train_data_aug)\n",
        "set_seed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neOgpatPlfga"
      },
      "outputs": [],
      "source": [
        "train_data_aug = torch.utils.data.ConcatDataset(lst_aug)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aW2gTjVF3GM"
      },
      "outputs": [],
      "source": [
        "# Divide data into training and validation (0.8 and 0.2)\n",
        "ratio = 0.8\n",
        "n_train_examples = int(len(train_data_aug) * ratio)\n",
        "n_val_examples = len(train_data_aug) - n_train_examples\n",
        "\n",
        "train_data, val_data = data.random_split(train_data_aug, [n_train_examples, n_val_examples])\n",
        "\n",
        "print(f\"Number of training samples = {len(train_data)}\")\n",
        "print(f\"Number of validation samples = {len(val_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "627vSssnF-LB"
      },
      "outputs": [],
      "source": [
        "## 너무 오래걸림 ㅠ\n",
        "# # Plot histogram for training and validation data\n",
        "\n",
        "\n",
        "# train_hist = [0]*numClasses\n",
        "# for i, value in enumerate(train_data):\n",
        "#     data, label = value\n",
        "#     train_hist[int(label)] += 1\n",
        "    \n",
        "# val_hist = [0]*numClasses\n",
        "# for i, value in enumerate(val_data):\n",
        "#     data, label = value\n",
        "#     train_hist[int(label)] += 1\n",
        "\n",
        "# plt.bar(range(numClasses), train_hist, label=\"train\")\n",
        "# # plt.bar(range(numClasses), val_hist, label=\"val\")\n",
        "# legend = plt.legend(loc='upper right', shadow=True)\n",
        "# plt.title(\"Distribution Plot\")\n",
        "# plt.xlabel(\"Class ID\")\n",
        "# plt.ylabel(\"# of examples\")\n",
        "\n",
        "# plt.savefig(\"train_val_split.png\", bbox_inches = 'tight', pad_inches=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7kG9-KpGDi-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create data loader for training and validation\n",
        "\n",
        "# DataLoader(\n",
        "#     train_dataset,\n",
        "#     batch_size=batch_size,\n",
        "#     num_workers=num_workers,\n",
        "#     worker_init_fn=seed_worker\n",
        "# )\n",
        "train_aug_loader = DataLoader(train_data_aug, shuffle=True, batch_size = BATCH_SIZE)\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size = BATCH_SIZE)\n",
        "val_loader = DataLoader(val_data, shuffle=True, batch_size = BATCH_SIZE)\n",
        "\n",
        "# print(train_data_all[0][0].shape)\n",
        "# print(train_data_all[0][1])\n",
        "# print(len(train_data_all.samples))\n",
        "# print(len(train_data_all.targets))\n",
        "# print(len(train_data_all.classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqQOw8924wIN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S71lBlsJFGx_"
      },
      "outputs": [],
      "source": [
        "# Test_Label\n",
        "test_ans = pd.read_csv('Test_Label.csv')\n",
        "\n",
        "# Create Folder\n",
        "os.mkdir('./Test_ans/')\n",
        "for i in range(43) : \n",
        "  path = './Test_ans/'+str(i)\n",
        "  if os.path.isdir(path) : \n",
        "    # os.rmdir(path)\n",
        "    print('existing' + path)\n",
        "  else : \n",
        "    os.mkdir(path)\n",
        "\n",
        "# file path move for answer data validation\n",
        "\n",
        "for f in  test_ans.iterrows():\n",
        "  filename = f[1]['Filename']\n",
        "  src = './Test/'\n",
        "  dir = './Test_ans/'+str(f[1]['ClassId']) + '/'\n",
        "  shutil.copy(src + filename, dir + filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okUrrtJlSh1X"
      },
      "outputs": [],
      "source": [
        "  # Define path of answer data\n",
        "answer_data_path = \"./Test_ans\"\n",
        "answer_data = torchvision.datasets.ImageFolder(root = answer_data_path, transform = data_transforms)\n",
        "print(f\"Number of answer samples = {len(answer_data)}\")\n",
        "answer_loader = DataLoader(answer_data, shuffle=False, batch_size = BATCH_SIZE)\n",
        "# answer_loader = DataLoader(answer_data, shuffle=False, batch_size = BATCH_SIZE)\n",
        "# print(answer_data.classes)\n",
        "# print(answer_data.class_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vkn6K_5SSty-"
      },
      "outputs": [],
      "source": [
        "# Plot histogram for ans data\n",
        "\n",
        "ans_hist = [0]*numClasses\n",
        "for i, value in enumerate(answer_data):\n",
        "    data, label = value\n",
        "    ans_hist[label] += 1\n",
        "\n",
        "plt.bar(range(numClasses), ans_hist, label=\"answer\")\n",
        "legend = plt.legend(loc='upper right', shadow=True)\n",
        "plt.title(\"Distribution Plot\")\n",
        "plt.xlabel(\"Class ID\")\n",
        "plt.ylabel(\"# of examples\")\n",
        "\n",
        "plt.savefig(\"answer.png\", bbox_inches = 'tight', pad_inches=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Chv3wtjt3bO1"
      },
      "outputs": [],
      "source": [
        "train_img = []  # imagefolder dataset 메모리에 올리기 위해 extract list\n",
        "train_lab = []  \n",
        "for (data, label) in train_data_aug :\n",
        "  # print(label, data.shape)\n",
        "  # print(data.numpy().shape)\n",
        "  train_img.append(data.numpy())\n",
        "  train_lab.append(label)\n",
        "  # break\n",
        "train_img = np.array(train_img)\n",
        "train_lab = np.array(train_lab)\n",
        "print(train_img.shape)\n",
        "print(train_lab.shape)\n",
        "train_img.reshape(len(train_lab), -1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DMyproJ3rNJ"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "\n",
        "smote = SMOTE(random_state = 0, k_neighbors = 5)\n",
        "image_smote, label_smote = smote.fit_resample(train_img.reshape(len(train_lab), -1), train_lab)\n",
        "s = train_img.shape\n",
        "image_smote = image_smote.reshape(-1, s[1], s[2], s[3])\n",
        "print(image_smote.shape)\n",
        "print(label_smote.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWrXgZx46-kd"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "image_tensor = torch.tensor(image_smote, dtype=torch.float32)#.to(\"cuda:0\")\n",
        "label_tensor = torch.tensor(label_smote, dtype=torch.int64)#.to(\"cuda:0\")\n",
        "# from torch.utils.data import TensorDataset, DataLoader\n",
        "train_ds = TensorDataset(image_tensor, label_tensor)\n",
        "print(type(train_ds))\n",
        "train_ds_loader = DataLoader(train_ds, shuffle=True, batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4KVhbUs_RWR"
      },
      "outputs": [],
      "source": [
        "# Plot histogram for training and validation data\n",
        "\n",
        "train_hist = [0]*numClasses\n",
        "for i, value in enumerate(train_ds):\n",
        "    data, label = value\n",
        "    # print(i, int(label), data.shape)\n",
        "    # break\n",
        "    train_hist[int(label)] += 1\n",
        "\n",
        "plt.bar(range(numClasses), train_hist, label=\"train\")\n",
        "legend = plt.legend(loc='upper right', shadow=True)\n",
        "plt.title(\"Distribution Plot\")\n",
        "plt.xlabel(\"Class ID\")\n",
        "plt.ylabel(\"# of examples\")\n",
        "\n",
        "plt.savefig(\"train_smote_split.png\", bbox_inches = 'tight', pad_inches=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPwLTv3P4VGT"
      },
      "outputs": [],
      "source": [
        "# for i, value in enumerate(train_ds):\n",
        "#     data, label = value\n",
        "#     print(label, data.shape)\n",
        "#     break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0vMoQWMH4dD"
      },
      "source": [
        "# MicronNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEfHrwvvCnBz"
      },
      "outputs": [],
      "source": [
        "nclasses = 43 # GTSRB as 43 classes\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 1, kernel_size=1)\n",
        "        self.conv2 = nn.Conv2d(1, 29, kernel_size=5)\n",
        "        self.maxpool2 = nn.MaxPool2d(3, stride=2 , ceil_mode=True)\n",
        "        self.conv3 = nn.Conv2d(29, 59, kernel_size=3)\n",
        "        self.maxpool3 = nn.MaxPool2d(3, stride=2 , ceil_mode=True)\n",
        "        self.conv4 = nn.Conv2d(59, 74, kernel_size=3)\n",
        "        self.maxpool4 = nn.MaxPool2d(3, stride=2 , ceil_mode=True)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.conv3_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(1184, 300)\n",
        "        self.fc2 = nn.Linear(300, nclasses)\n",
        "        self.conv0_bn = nn.BatchNorm2d(3)\n",
        "        self.conv1_bn = nn.BatchNorm2d(1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(29)\n",
        "        self.conv3_bn = nn.BatchNorm2d(59)\n",
        "        self.conv4_bn = nn.BatchNorm2d(74)\n",
        "        self.dense1_bn = nn.BatchNorm1d(300)\n",
        "    def forward(self, x):\n",
        "        x =  F.relu(self.conv1_bn(self.conv1(self.conv0_bn(x))))\n",
        "        x = F.relu(self.conv2_bn(self.conv2(x)))\n",
        "        x = F.relu(self.conv3_bn(self.conv3( self.maxpool2(x))))\n",
        "        x = F.relu(self.conv4_bn(self.conv4( self.maxpool3(x))))\n",
        "        x = self.maxpool4(x)        \n",
        "        x = x.view(-1, 1184)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dense1_bn(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        return F.log_softmax(x, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoqolZK7CtKd"
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "# epochs = 10000\n",
        "batch_size = 50\n",
        "seed = 1\n",
        "log_interval=180\n",
        "data = \"data\"\n",
        "torch.manual_seed(1)\n",
        "lr =0.007\n",
        "momentum = 0.9\n",
        "# step = 1000\n",
        "step = 50\n",
        "decay =  0.9996\n",
        "l2_norm = 0.00001\n",
        "cuda = True\n",
        "resume = False\n",
        "# These may change as described in paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwuR7v1yGYKc"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net()\n",
        "if  cuda: \n",
        "    model.to(device)\n",
        "\n",
        "if resume :\n",
        "    state_dict = torch.load(\"model_28.pth\")\n",
        "    model.load_state_dict(state_dict) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbf6PcZmGcwL"
      },
      "outputs": [],
      "source": [
        "# https://stackoverflow.com/questions/65318064/can-i-trainoptimize-on-f1-score-loss-with-pytorch\n",
        "# https://stackoverflow.com/questions/53354176/how-to-use-f-score-as-error-function-to-train-neural-networks\n",
        "# loss <-- F-Measure as the Error Function to Train Neural Networks \n",
        "#\n",
        "\n",
        "def validation():\n",
        "    model.eval()\n",
        "    validation_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in answer_loader:\n",
        "            # data, target = Variable(data), Variable(target)\n",
        "            data = data.to(device)\n",
        "            target =target.to(device)\n",
        "            output = model(data)\n",
        "            validation_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "        validation_loss /= len(val_loader.dataset)\n",
        "        print(f\"\\nValidation set: Average loss: {format(validation_loss, '.4f')}, Accuracy: {correct}/{len(answer_loader.dataset)} ({format(100. * correct / len(answer_loader.dataset), '.0f')}%)\\n\")\n",
        "    return validation_loss\n",
        "\n",
        "\n",
        "def train(epoch , train_loader):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target).cuda()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(f\"Train Epoch: {epoch}\\t[{batch_idx * len(data)}/{len(train_loader.dataset)}\\t({format(100. * batch_idx / len(train_loader),'.0f')}%)]\\tLoss: {format(loss.item(),'.6f')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfDQTP5LGlMy"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr , momentum=momentum, weight_decay=l2_norm, nesterov=True)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=decay)\n",
        "# train_ds_loader train_aug_loader\n",
        "temp = 10\n",
        "epochs = 20\n",
        "for epoch in range(1, epochs):\n",
        "    train(epoch, train_aug_loader)\n",
        "    val = validation()\n",
        "    if epoch % step == 0 :\n",
        "        scheduler.step()\n",
        "    if val < temp : \n",
        "        temp = val\n",
        "        model_file = 'model_' + str(epoch) + '.pth'\n",
        "        torch.save(model.state_dict(), model_file)\n",
        "        print('\\nSaved model to ' + model_file + '. You can run `python evaluate.py ' + model_file + '` to generate the Kaggle formatted csv file')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wDxPAi3Hwas"
      },
      "outputs": [],
      "source": [
        "# Print confusion matrix\n",
        "\n",
        "def plot_confusion_matrix(labels, pred_labels, classes):\n",
        "    \n",
        "    fig = plt.figure(figsize = (20, 20));\n",
        "    ax = fig.add_subplot(1, 1, 1);\n",
        "    cm = confusion_matrix(labels, pred_labels);\n",
        "    cm = ConfusionMatrixDisplay(cm, display_labels = classes);\n",
        "    cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\n",
        "    plt.xticks(rotation = 20)\n",
        "    \n",
        "labels_arr = range(0, nclasses)\n",
        "# plot_confusion_matrix(labels_list, y_pred_list, labels_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "759z-JqFHx16"
      },
      "outputs": [],
      "source": [
        "# Load the saved model\n",
        "\n",
        "model = Net()\n",
        "model.load_state_dict(torch.load(model_file)) # 'model_35.pth'\n",
        "model = model.cuda()\n",
        "\n",
        "# model = Net()\n",
        "# model.load_state_dict(torch.load('model_35.pth')) # 'model_35.pth'\n",
        "# model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpaijPuzH0SX"
      },
      "outputs": [],
      "source": [
        "test_answer = pd.read_csv('Test_Label.csv')\n",
        "test_answer[\"pred_class\"] = -1\n",
        "\n",
        "num = range(nclasses)\n",
        "labels = []\n",
        "for i in num:\n",
        "    labels.append(str(i))\n",
        "labels = sorted(labels)\n",
        "for i in num:\n",
        "    labels[i] = int(labels[i])\n",
        "\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize([48, 48]),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB])\n",
        "])\n",
        "\n",
        "\n",
        "# Perform classification\n",
        "\n",
        "y_pred_list = []\n",
        "corr_classified = 0\n",
        "numExamples = len(test_answer)\n",
        "\n",
        "##\n",
        "labels_list = []\n",
        "wronng_list = []\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for f_name in test_answer[\"Filename\"]:\n",
        "        image = Image.open(f\"Test//{f_name}\")\n",
        "\n",
        "        image = test_transforms(image)\n",
        "        image = torch.unsqueeze(image, 0)\n",
        "        # image = Variable(image)\n",
        "        image = image.to(device)\n",
        "\n",
        "        y_test_pred = model(image)\n",
        "        y_pred_tags = y_test_pred.data.max(1, keepdim=True)[1]\n",
        "        y_pred_tags = y_pred_tags.cpu().numpy()\n",
        "        # print(y_pred_tags)\n",
        "\n",
        "        y_pred = y_pred_tags[0][0]\n",
        "        y_pred = labels[y_pred]\n",
        "        \n",
        "        y_pred_list.append(y_pred)\n",
        "\n",
        "        # test_answer.loc[test_answer[test_answer[\"Filename\"] == f_name].index, \"pred_class\"] = y_pred\n",
        "        if test_answer[test_answer[\"Filename\"] == f_name][\"ClassId\"].values[0] == y_pred:\n",
        "            corr_classified += 1\n",
        "        else : \n",
        "            wronng_list.append([f_name,test_answer[test_answer[\"Filename\"] == f_name][\"ClassId\"].values[0], y_pred])\n",
        "        # i += 1\n",
        "\n",
        "df = pd.DataFrame(wronng_list) ## 데이터프래임 생성\n",
        "df.to_csv('wronng_list.csv',index=False) ## 구분자를 탭으로 하여 저장. 인덱스칼럼은 저장 안함.\n",
        "\n",
        "print(\"Number of correctly classified images = %d\" % corr_classified)\n",
        "print(\"Number of incorrectly classified images = %d\" % (numExamples - corr_classified))\n",
        "print(\"Final accuracy = %f\" % (corr_classified / numExamples))\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(test_answer.ClassId, y_pred_list, digits=5))\n",
        "\n",
        "plot_confusion_matrix(test_answer.ClassId, y_pred_list, labels_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swp4h1wrCxxs"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkGUnAosCn00"
      },
      "source": [
        "# AlexnetTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Br_3x46J4wF9"
      },
      "outputs": [],
      "source": [
        "# # Function to count the number of parameters in the model\n",
        "\n",
        "# def count_parameters(model):\n",
        "#     return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlXzwNCO6Ir9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import torch.nn as nn\n",
        "\n",
        "# class AlexnetTS(nn.Module):\n",
        "#     def __init__(self, output_dim):\n",
        "#         super().__init__()\n",
        "        \n",
        "#         self.features = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1),\n",
        "#             nn.MaxPool2d(kernel_size=2),\n",
        "#             nn.ReLU(inplace=True),\n",
        "            \n",
        "#             nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, padding=1),\n",
        "#             nn.MaxPool2d(kernel_size=2),\n",
        "#             nn.ReLU(inplace=True),\n",
        "            \n",
        "#             nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(inplace=True),\n",
        "            \n",
        "#             nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(inplace=True),\n",
        "            \n",
        "#             nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "#             nn.MaxPool2d(kernel_size=2),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             )\n",
        "        \n",
        "#         self.classifier = nn.Sequential(\n",
        "#             nn.Dropout(0.5),\n",
        "#             nn.Linear(256*7*7, 1000),\n",
        "#             nn.ReLU(inplace=True),\n",
        "            \n",
        "#             nn.Dropout(0.5),\n",
        "#             nn.Linear(in_features=1000, out_features=256),\n",
        "#             nn.ReLU(inplace=True),\n",
        "            \n",
        "#             nn.Linear(256, output_dim)\n",
        "#             )\n",
        "        \n",
        "#     def forward(self, x):\n",
        "#         x = self.features(x)\n",
        "#         h = x.view(x.shape[0], -1)\n",
        "#         x = self.classifier(h)\n",
        "#         return x, h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqKrS1iv4wDN"
      },
      "outputs": [],
      "source": [
        "# # Initialize the model\n",
        "# # The model is defined in the class AlexnetTS in the file class_alexnetTS.py\n",
        "\n",
        "# model = AlexnetTS(numClasses)\n",
        "# print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "# # Define optimizer and criterion functions\n",
        "\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# # If CUDA is available, convert model and loss to cuda variables\n",
        "\n",
        "# if torch.cuda.is_available():\n",
        "#     model = model.cuda()\n",
        "#     criterion = criterion.cuda()\n",
        "\n",
        "# # Print model\n",
        "# print(model)\n",
        "\n",
        "# # Print summary of the model for the given dimension of the image\n",
        "# print(summary(model, (3, 48, 48))) \n",
        "\n",
        "# # Print model's state dict\n",
        "# print(\"Model's state dict:\")\n",
        "# for param_tensor in model.state_dict():\n",
        "#     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "# print(\"\")\n",
        "\n",
        "# # Print optimizer details\n",
        "\n",
        "# print(\"Optimizer details:\")\n",
        "# print(optimizer)\n",
        "# print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4udNIGcd6Okp"
      },
      "outputs": [],
      "source": [
        "# # Function to calculate accuracy\n",
        "\n",
        "# def calculate_accuracy(y_pred, y):\n",
        "#     top_pred = y_pred.argmax(1, keepdim = True)\n",
        "#     correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "#     acc = correct.float() / y.shape[0]\n",
        "#     return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CV-i2c9r6Ohq"
      },
      "outputs": [],
      "source": [
        "# # Function to perform training of the model\n",
        "\n",
        "# def train(model, loader, opt, criterion):\n",
        "#     epoch_loss = 0\n",
        "#     epoch_acc = 0\n",
        "    \n",
        "#     # Train the model\n",
        "#     model.train()\n",
        "    \n",
        "#     for (images, labels) in loader:\n",
        "#         images = images.cuda()\n",
        "#         labels = labels.cuda()\n",
        "#         # labels = labels.cuda().type(torch.LongTensor)\n",
        "        \n",
        "#         # Training pass\n",
        "#         opt.zero_grad()\n",
        "        \n",
        "#         output, _ = model(images)\n",
        "#         loss = criterion(output, labels)\n",
        "        \n",
        "#         # Backpropagation\n",
        "#         loss.backward()\n",
        "        \n",
        "#         # Calculate accuracy\n",
        "#         acc = calculate_accuracy(output, labels)\n",
        "        \n",
        "#         # Optimizing weights\n",
        "#         opt.step()\n",
        "        \n",
        "#         epoch_loss += loss.item()\n",
        "#         epoch_acc += acc.item()\n",
        "        \n",
        "#     return epoch_loss / len(loader), epoch_acc / len(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUgvxmLZ6dKf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Function to perform evaluation on the trained model\n",
        "\n",
        "# def evaluate(model, loader, opt, criterion):\n",
        "#     epoch_loss = 0\n",
        "#     epoch_acc = 0\n",
        "    \n",
        "#     # Evaluate the model\n",
        "#     model.eval()\n",
        "    \n",
        "#     with torch.no_grad():\n",
        "#         for (images, labels) in loader:\n",
        "#             images = images.cuda()\n",
        "#             labels = labels.cuda()\n",
        "            \n",
        "#             # Run predictions\n",
        "#             output, _ = model(images)\n",
        "#             loss = criterion(output, labels)\n",
        "            \n",
        "#             # Calculate accuracy\n",
        "#             acc = calculate_accuracy(output, labels)\n",
        "            \n",
        "#             epoch_loss += loss.item()\n",
        "#             epoch_acc += acc.item()\n",
        "    \n",
        "#     return epoch_loss / len(loader), epoch_acc / len(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Io7bYHm56dHf"
      },
      "outputs": [],
      "source": [
        "# # Perform training\n",
        "# local_epoch = 50\n",
        "# # List to save training and val loss and accuracies\n",
        "# # train_loss_list = [0]*EPOCHS\n",
        "# # train_acc_list = [0]*EPOCHS\n",
        "# # val_loss_list = [0]*EPOCHS\n",
        "# # val_acc_list = [0]*EPOCHS\n",
        "# train_loss_list = [0]*local_epoch\n",
        "# train_acc_list = [0]*local_epoch\n",
        "# val_loss_list = [0]*local_epoch\n",
        "# val_acc_list = [0]*local_epoch\n",
        "\n",
        "# # for epoch in range(EPOCHS):\n",
        "# for epoch in range(local_epoch):\n",
        "#     print(\"Epoch-%d: \" % (epoch))\n",
        "\n",
        "#     train_start_time = time.monotonic()\n",
        "#     # train_loss, train_acc = train(model, answer_loader, optimizer, criterion)\n",
        "#     # train_loss, train_acc = train(model, train_all_loader, optimizer, criterion)\n",
        "#     train_loss, train_acc = train(model, train_aug_loader, optimizer, criterion)\n",
        "#     train_end_time = time.monotonic()\n",
        "\n",
        "#     val_start_time = time.monotonic()\n",
        "#     # val_loss, val_acc = evaluate(model, val_loader, optimizer, criterion) # val data\n",
        "#     val_loss, val_acc = evaluate(model, answer_loader, optimizer, criterion) # answer data\n",
        "#     val_end_time = time.monotonic()\n",
        "    \n",
        "#     train_loss_list[epoch] = train_loss\n",
        "#     train_acc_list[epoch] = train_acc\n",
        "#     val_loss_list[epoch] = val_loss\n",
        "#     val_acc_list[epoch] = val_acc\n",
        "    \n",
        "#     print(\"Training: Loss = %.4f, Accuracy = %.4f, Time = %.2f seconds\" % (train_loss, train_acc, train_end_time - train_start_time))\n",
        "#     print(\"Validation: Loss = %.4f, Accuracy = %.4f, Time = %.2f seconds\" % (val_loss, val_acc, val_end_time - val_start_time))\n",
        "#     print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcQql-6A6dDh"
      },
      "outputs": [],
      "source": [
        "# # Saving the model\n",
        "\n",
        "# # Create folder to save model\n",
        "# MODEL_FOLDER = \"./Model\"\n",
        "# if not os.path.isdir(MODEL_FOLDER):\n",
        "#     os.mkdir(MODEL_FOLDER)\n",
        "    \n",
        "# PATH_TO_MODEL = MODEL_FOLDER + \"/pytorch_classification_alexnetTS.pth\"\n",
        "# if os.path.exists(PATH_TO_MODEL):\n",
        "#     os.remove(PATH_TO_MODEL)\n",
        "# torch.save(model.state_dict(), PATH_TO_MODEL)\n",
        "\n",
        "# print(\"Model saved at %s\" %(PATH_TO_MODEL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ8oUwt36auj"
      },
      "outputs": [],
      "source": [
        "# # Plot loss and accuracies for training and validation data\n",
        "\n",
        "# _, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# # Loss plot\n",
        "# axs[0].plot(train_loss_list, label=\"train\")\n",
        "# axs[0].plot(val_loss_list, label=\"val\")\n",
        "# axs[0].set_title(\"Plot - Loss\")\n",
        "# axs[0].set_xlabel(\"Epochs\")\n",
        "# axs[0].set_ylabel(\"Loss\")\n",
        "# legend = axs[0].legend(loc='upper right', shadow=False)\n",
        "\n",
        "# # Accuracy plot\n",
        "# axs[1].plot(train_acc_list, label=\"train\")\n",
        "# axs[1].plot(val_acc_list, label=\"val\")\n",
        "# axs[1].set_title(\"Plot - Accuracy\")\n",
        "# axs[1].set_xlabel(\"Epochs\")\n",
        "# axs[1].set_ylabel(\"Accuracy\")\n",
        "# legend = axs[1].legend(loc='center right', shadow=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enSqV0IF6ayh"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQAoGPn4CosN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIbPWWEpC63A"
      },
      "outputs": [],
      "source": [
        "# test_answer = pd.read_csv('Test_Label.csv')\n",
        "# test_answer[\"pred_class\"] = -1\n",
        "\n",
        "# num = range(numClasses)\n",
        "# labels = []\n",
        "# for i in num:\n",
        "#     labels.append(str(i))\n",
        "# labels = sorted(labels)\n",
        "# for i in num:\n",
        "#     labels[i] = int(labels[i])\n",
        "\n",
        "# # Perform classification\n",
        "# # test_transforms = transforms.Compose([\n",
        "# #     transforms.Resize([112, 112]),\n",
        "# #     transforms.ToTensor()\n",
        "# #     ])\n",
        "# test_transforms = transforms.Compose([\n",
        "#     transforms.Resize([48, 48]),\n",
        "#     transforms.ToTensor(),\n",
        "#     # transforms.Normalize(mean=1, std=0.5)\n",
        "#     ])\n",
        "        \n",
        "# y_pred_list = []\n",
        "# corr_classified = 0\n",
        "# numExamples = len(test_answer)\n",
        "\n",
        "# ##\n",
        "# labels_list = []\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     model.eval()\n",
        "#     for f_name in test_answer[\"Filename\"]:\n",
        "#         image = Image.open(f\"Test//{f_name}\")\n",
        "\n",
        "#         image = test_transforms(image)\n",
        "#         image = torch.unsqueeze(image, 0)\n",
        "#         image = image.cuda()\n",
        "\n",
        "#         y_test_pred = model(image)\n",
        "\n",
        "#         y_pred_softmax = torch.log_softmax(y_test_pred[0], dim=1)\n",
        "#         _, y_pred_tags = torch.max(y_pred_softmax, dim=1)\n",
        "#         y_pred_tags = y_pred_tags.cpu().numpy()\n",
        "\n",
        "#         y_pred = y_pred_tags[0]\n",
        "#         y_pred = labels[y_pred]\n",
        "        \n",
        "#         y_pred_list.append(y_pred)\n",
        "\n",
        "#         test_answer.loc[test_answer[test_answer[\"Filename\"] == f_name].index, \"pred_class\"] = y_pred\n",
        "#         if test_answer[test_answer[\"Filename\"] == f_name][\"ClassId\"].values[0] == y_pred:\n",
        "#             corr_classified += 1\n",
        "\n",
        "#         # i += 1\n",
        "\n",
        "# print(\"Number of correctly classified images = %d\" % corr_classified)\n",
        "# print(\"Number of incorrectly classified images = %d\" % (numExamples - corr_classified))\n",
        "# print(\"Final accuracy = %f\" % (corr_classified / numExamples))\n",
        "\n",
        "# # Print classification report\n",
        "# print(classification_report(test_answer.ClassId, test_answer.pred_class))\n",
        "\n",
        "# # plot_confusion_matrix(test_answer.ClassId, test_answer.pred_class, labels_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wq_hU_ibC6zh"
      },
      "outputs": [],
      "source": [
        "# Number of correctly classified images = 8452\n",
        "# Number of incorrectly classified images = 218\n",
        "# Final accuracy = 0.974856\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#            0       1.00      1.00      1.00        60\n",
        "#            1       0.99      0.99      0.99       420\n",
        "#            2       0.97      0.97      0.97       420\n",
        "#            3       0.96      0.99      0.97       420\n",
        "#            4       1.00      0.98      0.99       420\n",
        "#            5       0.98      0.97      0.97       420\n",
        "#            6       1.00      0.87      0.93        60\n",
        "#            7       0.99      1.00      1.00       420\n",
        "#            8       1.00      0.99      0.99       420\n",
        "#            9       1.00      1.00      1.00       420\n",
        "#           10       1.00      0.99      1.00       420\n",
        "#           11       0.94      0.99      0.97       420\n",
        "#           12       0.99      0.98      0.99       420\n",
        "#           13       0.99      0.99      0.99       420\n",
        "#           14       1.00      1.00      1.00       210\n",
        "#           15       0.99      0.99      0.99       210\n",
        "#           16       1.00      1.00      1.00        60\n",
        "#           17       1.00      1.00      1.00       210\n",
        "#           18       0.98      0.87      0.92       210\n",
        "#           19       0.98      1.00      0.99        60\n",
        "#           20       0.92      0.98      0.95        60\n",
        "#           21       0.98      0.75      0.85        60\n",
        "#           22       1.00      0.98      0.99        60\n",
        "#           23       1.00      0.80      0.89        60\n",
        "#           24       0.97      0.95      0.96        60\n",
        "#           25       0.99      0.98      0.98       420\n",
        "#           26       1.00      0.92      0.96        60\n",
        "#           27       0.79      0.55      0.65        60\n",
        "#           28       0.78      0.98      0.87        60\n",
        "#           29       0.88      1.00      0.94        60\n",
        "#           30       0.61      0.58      0.60        60\n",
        "#           31       0.90      0.99      0.94       210\n",
        "#           32       0.83      1.00      0.91        60\n",
        "#           33       0.99      0.99      0.99       210\n",
        "#           34       1.00      1.00      1.00        60\n",
        "#           35       1.00      1.00      1.00       210\n",
        "#           36       0.98      1.00      0.99        60\n",
        "#           37       1.00      1.00      1.00        60\n",
        "#           38       1.00      0.99      0.99       420\n",
        "#           39       0.94      0.98      0.96        60\n",
        "#           40       1.00      0.97      0.98        60\n",
        "#           41       0.79      0.93      0.85        60\n",
        "#           42       1.00      1.00      1.00        60\n",
        "\n",
        "#     accuracy                           0.97      8670\n",
        "#    macro avg       0.96      0.95      0.95      8670\n",
        "# weighted avg       0.98      0.97      0.97      8670"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hmdIRS6C6w5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amiON7YmC6tl"
      },
      "outputs": [],
      "source": [
        "# test_answer = pd.read_csv('Test_Label.csv')\n",
        "# test_answer[\"pred_class\"] = -1\n",
        "\n",
        "# num = range(numClasses)\n",
        "# labels = []\n",
        "# for i in num:\n",
        "#     labels.append(str(i))\n",
        "# labels = sorted(labels)\n",
        "# for i in num:\n",
        "#     labels[i] = int(labels[i])\n",
        "\n",
        "# # Perform classification\n",
        "# test_transforms = transforms.Compose([\n",
        "#     transforms.Resize([48, 48]),\n",
        "#     transforms.ToTensor(),\n",
        "#     # transforms.Normalize(mean=1, std=0.5)\n",
        "#     ])\n",
        "        \n",
        "# y_pred_list = []\n",
        "# corr_classified = 0\n",
        "# numExamples = len(test_answer)\n",
        "\n",
        "# ##\n",
        "# labels_list = []\n",
        "# wronng_list = []\n",
        "# with torch.no_grad():\n",
        "#     model.eval()\n",
        "#     for f_name in test_answer[\"Filename\"]:\n",
        "#         image = Image.open(f\"Test//{f_name}\")\n",
        "\n",
        "#         image = test_transforms(image)\n",
        "#         image = torch.unsqueeze(image, 0)\n",
        "#         image = image.cuda()\n",
        "\n",
        "#         y_test_pred = model(image)\n",
        "\n",
        "#         y_pred_softmax = torch.log_softmax(y_test_pred[0], dim=1)\n",
        "#         _, y_pred_tags = torch.max(y_pred_softmax, dim=1)\n",
        "#         y_pred_tags = y_pred_tags.cpu().numpy()\n",
        "\n",
        "#         y_pred = y_pred_tags[0]\n",
        "#         y_pred = labels[y_pred]\n",
        "        \n",
        "#         y_pred_list.append(y_pred)\n",
        "\n",
        "#         test_answer.loc[test_answer[test_answer[\"Filename\"] == f_name].index, \"pred_class\"] = y_pred\n",
        "#         if test_answer[test_answer[\"Filename\"] == f_name][\"ClassId\"].values[0] == y_pred:\n",
        "#             corr_classified += 1\n",
        "#         else : \n",
        "#           wronng_list.append([f_name,test_answer[test_answer[\"Filename\"] == f_name][\"ClassId\"].values[0], y_pred])\n",
        "#         # i += 1\n",
        "\n",
        "# print(\"Number of correctly classified images = %d\" % corr_classified)\n",
        "# print(\"Number of incorrectly classified images = %d\" % (numExamples - corr_classified))\n",
        "# print(\"Final accuracy = %f\" % (corr_classified / numExamples))\n",
        "\n",
        "# # Print classification report\n",
        "# print(classification_report(test_answer.ClassId, test_answer.pred_class))\n",
        "\n",
        "# # plot_confusion_matrix(test_answer.ClassId, test_answer.pred_class, labels_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zzUgULmK7N2"
      },
      "outputs": [],
      "source": [
        "# df = pd.DataFrame(wronng_list) ## 데이터프래임 생성\n",
        "# df.to_csv('wronng_list.csv',index=False) ## 구분자를 탭으로 하여 저장. 인덱스칼럼은 저장 안함."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45ikcSy1Nck8"
      },
      "outputs": [],
      "source": [
        "# # Print confusion matrix\n",
        "\n",
        "# def plot_confusion_matrix(labels, pred_labels, classes):\n",
        "    \n",
        "#     fig = plt.figure(figsize = (20, 20));\n",
        "#     ax = fig.add_subplot(1, 1, 1);\n",
        "#     # print(labels)\n",
        "#     # print(pred_labels)\n",
        "#     cm = confusion_matrix(labels, pred_labels);\n",
        "#     cm = ConfusionMatrixDisplay(cm, display_labels = classes);\n",
        "#     cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\n",
        "#     plt.xticks(rotation = 20)\n",
        "    \n",
        "# labels_arr = range(0, numClasses)\n",
        "# # plot_confusion_matrix(test_answer.ClassId, test_answer.pred_class, labels_arr)\n",
        "# plot_confusion_matrix(test_answer.ClassId, y_pred_list, labels_arr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4tGLo0ZC87h"
      },
      "source": [
        "# test using val_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2-vPeG9Dx9s"
      },
      "outputs": [],
      "source": [
        "# val_data.dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhEZ9ZA28X3y"
      },
      "outputs": [],
      "source": [
        "# # Load the saved model\n",
        "\n",
        "# model = AlexnetTS(numClasses)\n",
        "# model.load_state_dict(torch.load(PATH_TO_MODEL))\n",
        "# model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exXGcoDSDqf2"
      },
      "outputs": [],
      "source": [
        "# # Perform classification\n",
        "\n",
        "# y_pred_list = []\n",
        "# corr_classified = 0\n",
        "# # numExamples = len(val_data)\n",
        "# numExamples = len(val_data)\n",
        "\n",
        "# ##\n",
        "# labels_list = []\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     model.eval()\n",
        "\n",
        "#     # i = 0\n",
        "\n",
        "#     for image, label_true in data.DataLoader(val_data, shuffle=True, batch_size = 1): # shuffle = False when test\n",
        "#         labels_list.append(label_true.cpu().numpy()[0])\n",
        "#         image = image.cuda()\n",
        "\n",
        "#         y_test_pred = model(image)\n",
        "\n",
        "#         y_pred_softmax = torch.log_softmax(y_test_pred[0], dim=1)\n",
        "#         _, y_pred_tags = torch.max(y_pred_softmax, dim=1)\n",
        "#         y_pred_tags = y_pred_tags.cpu().numpy()\n",
        "\n",
        "#         y_pred_list.append(y_pred_tags[0])\n",
        "#         if label_true == y_pred_tags[0]:\n",
        "#             corr_classified += 1\n",
        "\n",
        "#         # i += 1\n",
        "\n",
        "# print(\"Number of correctly classified images = %d\" % corr_classified)\n",
        "# print(\"Number of incorrectly classified images = %d\" % (numExamples - corr_classified))\n",
        "# print(\"Final accuracy = %f\" % (corr_classified / numExamples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TU_EmO68X1R"
      },
      "outputs": [],
      "source": [
        "# # Print classification report\n",
        "\n",
        "# print(classification_report(labels_list, y_pred_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nt3WOzxp8Xr0"
      },
      "outputs": [],
      "source": [
        "# # Print confusion matrix\n",
        "\n",
        "# def plot_confusion_matrix(labels, pred_labels, classes):\n",
        "    \n",
        "#     fig = plt.figure(figsize = (20, 20));\n",
        "#     ax = fig.add_subplot(1, 1, 1);\n",
        "#     cm = confusion_matrix(labels, pred_labels);\n",
        "#     cm = ConfusionMatrixDisplay(cm, display_labels = classes);\n",
        "#     cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\n",
        "#     plt.xticks(rotation = 20)\n",
        "    \n",
        "# labels_arr = range(0, numClasses)\n",
        "# plot_confusion_matrix(labels_list, y_pred_list, labels_arr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVSRSP2U6Odb"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MGJ3BMm4v0o"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDqMK4SShLID"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0H4N_W8YhLM7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QoNCLBahLQg"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfxpQwaOhLTb"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfX3pUtRhLWL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sinZx5pohLZK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjEffKPJhLb6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XufEUi4uhLe7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxPbfVHGhLhZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "traff_ver04_MicronNet_transformer_final.ipynb의 사본",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}